import os
import logging
import asyncio

from enum import Enum
from dotenv import load_dotenv
from pydantic import BaseModel
from langchain.prompts import PromptTemplate
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI

# from vector_store_db import check_vector_store, save_to_vector_store
# from vector_search import search_similar_code

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.DEBUG)

# LangChain LLM ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=GEMINI_API_KEY)

class CodeStyle(str, Enum):
    PEP8 = "PEP8"
    Google = "Google"
    NoneStyle = "None"

class CodeStructure(str, Enum):
    Functional = "functional"
    ClassBased = "class-based"

class CodeRequest(BaseModel):
    description: str
    style: CodeStyle = CodeStyle.PEP8
    include_comments: bool = True
    structure: CodeStructure = CodeStructure.Functional

class CodeGenerator:
    """Python ì½”ë“œ ìƒì„±ê¸° (RAG ë¯¸ì ìš©)"""

    @classmethod
    async def generate_code(cls, request: CodeRequest, model: str = "gemini-pro") -> str:
        """ë¹„ë™ê¸° Gemini API í˜¸ì¶œ (RAG ë¯¸ì ìš©)"""
        
        # # ê¸°ì¡´ ì½”ë“œ í™•ì¸ (Vector Store)
        # cached_code = check_vector_store(request.description)
        # if cached_code:
        #     return cached_code

        # # ìœ ì‚¬í•œ ì½”ë“œ ê²€ìƒ‰ (RAG)
        # similar_codes = search_similar_code(request.description, top_k=1)
        # similar_code_text = similar_codes[0][1] if similar_codes else "ì°¸ê³  ì½”ë“œ ì—†ìŒ"
        
        similar_code_text = "ì°¸ê³  ì½”ë“œ ì—†ìŒ"

        prompt = cls._generate_prompt(request, similar_code_text)

        # LangChain LLM í˜¸ì¶œ
        response = await asyncio.get_event_loop().run_in_executor(
            None, lambda: llm.invoke(prompt)
        )

        generated_code = response.content if isinstance(response, AIMessage) else "ì½”ë“œ ìƒì„± ì‹¤íŒ¨"

        # # Vector Storeì— ì €ì¥ (DB í™œìš©)
        # save_to_vector_store(request.description, generated_code)

        return generated_code

    @classmethod
    def _generate_prompt(cls, request: CodeRequest, similar_code: str) -> str:
        """LangChain PromptTemplateì„ ì‚¬ìš©í•œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ë³€í™˜ëœ ë¬¸ìì—´ ë³€ìˆ˜ ì •ì˜ (ì¼ê´€ëœ ë°©ì‹ ì ìš©)
        include_comments_text = "í¬í•¨" if request.include_comments else "ì œì™¸"
        structure_text = "í•¨ìˆ˜í˜•" if request.structure == "functional" else "í´ë˜ìŠ¤í˜•"

        template = PromptTemplate(
            input_variables=["description", "style", "include_comments", "structure", "similar_code"],
            template="""
            ë„ˆëŠ” Python ì½”ë“œ ìƒì„±ì„ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” AIì•¼.
            ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì½”ë“œê°€ **ì˜¬ë°”ë¥´ê²Œ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡** ì‘ì„±í•´ì•¼ í•´.

            ### ğŸ› ï¸ í•„ìˆ˜ ì¡°ê±´
            - Python ë¬¸ë²• ì˜¤ë¥˜(SyntaxError)ê°€ ì—†ì–´ì•¼ í•¨.
            - ì‹¤í–‰ ì‹œ ì˜¤ë¥˜(RuntimeError)ê°€ ë°œìƒí•˜ì§€ ì•Šì•„ì•¼ í•¨.
            - ì½”ë“œì˜ ë…¼ë¦¬ê°€ ì •í™•í•´ì•¼ í•˜ë©°, ì˜ˆìƒëœ ì¶œë ¥ì´ ë‚˜ì™€ì•¼ í•¨.

            ### ğŸ¨ ì½”ë“œ ìŠ¤íƒ€ì¼ & êµ¬ì¡°
            - ì½”ë“œ ìŠ¤íƒ€ì¼: {style}
            - ì£¼ì„ í¬í•¨ ì—¬ë¶€: {include_comments}
            - ì½”ë“œ êµ¬ì¡°: {structure}

            ### ğŸ¯ ì½”ë“œ ìƒì„± ìš”ì²­
            "{description}"

            ### ğŸ“ ì°¸ê³  ì½”ë“œ
            ```python
            {similar_code}
            ```
            """
        )

        return template.format(
            description=request.description,
            style=request.style.value,
            include_comments=include_comments_text,  
            structure=structure_text,
            similar_code=similar_code
        )